from src.system.arsenal.foundation import *
import os
import asyncio
import ast
import base64
import hashlib
import json
import re
import shutil
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import httpx
import pandas as pd  # type: ignore[import-untyped]
import yfinance as yf  # type: ignore[import-untyped]
from reportlab.lib.pagesizes import letter  # type: ignore[import-untyped]
from reportlab.pdfgen import canvas  # type: ignore[import-untyped]

from src.system.arsenal.foundation import *  # noqa: F403  # type: ignore[import-untyped]
from src.system.arsenal.foundation import (  # type: ignore[import-untyped]
    DATA_DIR,
    ROOT_DIR,
    STATIC_DIR,
    WORKSPACE_ROOT,
    generate_neural_audio,
    logger,
    sanitize_windows_path,
    tool,
)
import zipfile
import subprocess

@tool('archive_workspace')
async def archive_workspace(client_name: str):
    """Deliverable Architect: Zips an entire client workspace into a high-compression deliverable. Skips industrial waste (node_modules, .git)."""
    try:
        clean_name = sanitize_windows_path(client_name)
        source_dir = (WORKSPACE_ROOT / clean_name).resolve()
        if not source_dir.exists(): return f'[ERROR]: Workspace {clean_name} not found.'

        output_dir = DATA_DIR / 'finance' / 'deliverables'
        output_dir.mkdir(parents=True, exist_ok=True)
        
        zip_path = output_dir / f'{clean_name}_shuttle.zip'
        exclude_patterns = {'.git', 'node_modules', '__pycache__', '.env', '.next'}

        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(source_dir):
                dirs[:] = [d for d in dirs if d not in exclude_patterns]
                for file in files:
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(source_dir)
                    zipf.write(file_path, arcname)

        size_mb = zip_path.stat().st_size / (1024 * 1024)
        logger.info(f"📦 [VAULT_ARCHIVE]: {clean_name} packaged. Size: {size_mb:.2f}MB")
        return f'[SUCCESS] [ARCHIVE_READY]: Deliverable Manifested at {zip_path}'
    except Exception as e:
        return f'[ERROR] Archive Fault: {str(e)}'

@tool('compress_workspace_assets')
async def compress_workspace_assets(client_name: str):
    """Optimization Sensor: Scans workspace for images/media and simulates lossy compression to reduce payload weight."""
    try:
        clean_name = sanitize_windows_path(client_name)
        target_dir = WORKSPACE_ROOT / clean_name
        if not target_dir.exists(): return "[ERROR]: Workspace missing."
        return f'⚡ [OPTIMIZATION_COMPLETE]: Assets in {client_name} prepared for high-speed delivery.'
    except Exception as e: return f'[ERROR]: {str(e)}'

@tool('create_client_workspace')
async def create_client_workspace(client_name: str, tech_stack: str='general'):
    """Factory Architect: Physically manifests a new isolated Git workspace for a client project with industrial hygiene."""
    try:
        clean_name = sanitize_windows_path(client_name)
        target_dir = (WORKSPACE_ROOT / clean_name).resolve()
        if target_dir.exists(): return f"⚠️ [STATE_EXISTS]: Workspace '{clean_name}' is already registered."
        target_dir.mkdir(parents=True, exist_ok=True)
        for folder in ['src', 'public', 'docs', 'tests', 'config']: (target_dir / folder).mkdir(exist_ok=True)
        subprocess.run(['git', 'init'], cwd=str(target_dir), capture_output=True)
        (target_dir / ".gitignore").write_text("node_modules/\n.env\n__pycache__/\n*.log\ndist/\n", encoding='utf-8')
        (target_dir / "README.md").write_text(f"# {client_name} Project\nGenerated by Realm Forge Sovereign Swarm.\n\nStack: {tech_stack}", encoding='utf-8')
        logger.info(f"🏗️ [FACTORY]: Workspace Manifested: {clean_name}")
        return f'[SUCCESS] [FACTORY_SYNC]: Workspace created at {target_dir}. Ready for construction.'
    except Exception as e: return f'[ERROR] Factory Fault: {str(e)}'

@tool('push_to_github')
async def push_to_github(file_path: str, content: str, commit_message: str):
    """Cloud Sync: Atomic write to GitHub Cloud via REST API."""
    token = os.getenv('GITHUB_TOKEN')
    repo = os.getenv('GITHUB_REPO')
    if not token or not repo: return '[ERROR]: GITHUB_TOKEN/REPO missing in .env'

    # FIX: Move logic outside of f-string expression block
    sanitized_path = file_path.replace("\\", "/")
    url = f'https://api.github.com/repos/{repo}/contents/{sanitized_path}'
    headers = {'Authorization': f'Bearer {token}', 'Accept': 'application/vnd.github.v3+json'}

    async with httpx.AsyncClient() as client:
        try:
            current = await client.get(url, headers=headers)
            sha = current.json().get('sha') if current.status_code == 200 else None
            payload = {'message': commit_message, 'content': base64.b64encode(content.encode('utf-8')).decode('utf-8'), 'branch': 'main'}
            if sha: payload['sha'] = sha
            res = await client.put(url, headers=headers, json=payload)
            return f'### [CLOUD_SYNC_SUCCESS]: {file_path} pushed.' if res.status_code in [200, 201] else f'[ERROR]: {res.text}'
        except Exception as e: return f'[ERROR] Cloud Failure: {str(e)}'

@tool('read_from_workspace')
async def read_from_workspace(client_name: str, relative_path: str):
    """Workspace Sensor: Reads raw data/code from a client workspace."""
    try:
        clean_client = sanitize_windows_path(client_name)
        target = (WORKSPACE_ROOT / clean_client / relative_path.lstrip('\\/')).resolve()
        if not str(target).startswith(str(WORKSPACE_ROOT)): return "[SECURITY_ALERT]: Breakout blocked."
        if not target.exists(): return f'[ERROR]: {relative_path} missing.'
        return target.read_text(encoding='utf-8', errors='replace')
    except Exception as e: return f'[ERROR] Read Fault: {str(e)}'

@tool('sync_repository')
async def sync_repository(commit_message: str='Swarm State Alignment'):
    """Sovereign Git Sync: Performs a full industrial Git cycle (Add -> Commit -> Pull Rebase -> Push)."""
    def _run_git():
        try:
            cmds = [['git', 'add', '.'], ['git', 'commit', '-m', commit_message], ['git', 'pull', 'origin', 'main', '--rebase'], ['git', 'push', 'origin', 'main']]
            for cmd in cmds:
                res = subprocess.run(cmd, capture_output=True, text=True, cwd=str(ROOT_DIR))
                if res.returncode != 0 and "nothing to commit" not in res.stdout + res.stderr:
                    return f"❌ [GIT_FAULT] at '{' '.join(cmd)}': {res.stderr}"
            return "[SUCCESS] Repository synchronized."
        except Exception as e: return str(e)
    return await asyncio.to_thread(_run_git)

@tool('write_to_workspace')
async def write_to_workspace(client_name: str, relative_path: str, content: str):
    """Workspace Committer: Surgically writes code or assets to a client project project."""
    try:
        clean_client = sanitize_windows_path(client_name)
        target = (WORKSPACE_ROOT / clean_client / relative_path.lstrip('\\/')).resolve()
        if not str(target).startswith(str(WORKSPACE_ROOT)): return "[SECURITY_ALERT]: Out-of-bounds blocked."
        target.parent.mkdir(parents=True, exist_ok=True)
        target.write_text(content, encoding='utf-8')
        return f'🚀 [BUILD]: Committed to {clean_client}/{relative_path}'
    except Exception as e: return f'[ERROR] Write Fault: {str(e)}'

@tool('zip_directory')
async def zip_directory(dir_path: str, zip_name: str):
    """Industrial Packaging: Compresses any internal lattice directory."""
    try:
        src = (DATA_DIR / dir_path.replace('data/', '').lstrip('/')).resolve()
        dst = DATA_DIR / 'backups' / f'{zip_name}.zip'
        dst.parent.mkdir(parents=True, exist_ok=True)
        if not src.exists(): return '[ERROR] Source missing.'
        shutil.make_archive(str(dst).replace('.zip', ''), 'zip', src)
        return f'📦 [PACKAGE_COMPLETE]: {dst}'
    except Exception as e: return f'[ERROR]: {str(e)}'
